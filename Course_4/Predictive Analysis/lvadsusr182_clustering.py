# -*- coding: utf-8 -*-
"""LVADSUSR182_Clustering.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uqLVahoEUVOVCH3jFbfYNyVWW98xUk2n
"""

#SOLVING THIS USING 'K-Means Clustering'
import pandas as pd
from sklearn.preprocessing import StandardScaler,LabelEncoder
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('/content/customer_segmentation_fa.csv')

df.info()

df.isna().sum()

#Removing null values
df['Income'].fillna(df['Income'].mean(),inplace=True)

# converting the categorical columns into numerical for computation
le=LabelEncoder()
df['Education']=le.fit_transform(df['Education'])
df['Marital_Status']=le.fit_transform(df['Marital_Status'])
df['Dt_Customer']=le.fit_transform(df['Dt_Customer'])

#Finding null values for clustering
columns_for_clustering = ['Year_Birth','Response','Z_Revenue','Z_CostContact','Complain','AcceptedCmp2',
                          'AcceptedCmp1','AcceptedCmp5','AcceptedCmp4','NumWebVisitsMonth','NumStorePurchases',
                          'NumCatalogPurchases','NumWebPurchases','NumDealsPurchases','MntGoldProds','MntSweetProducts',
                          'MntFishProducts','MntFruits','Recency','Kidhome','Income','Teenhome','Marital_Status',
                          'Education','Year_Birth']
X = df[columns_for_clustering]

#Scaling the values of all the featured columns
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

#Now for the elbow method and derive number of clusters based on bent
wcss = []
for i in range(1, 11):
    kmeans = KMeans(n_clusters=i, init='k-means++', random_state=42)
    kmeans.fit(X_scaled)
    wcss.append(kmeans.inertia_)

plt.figure(figsize=(10, 6))
plt.plot(range(1, 11), wcss, marker='o', linestyle='--')
plt.title('Elbow Method')
plt.xlabel('Number of Clusters')
plt.ylabel('WCSS')
plt.xticks(range(1, 11))
plt.grid(True)
plt.show()

n_clusters = 3
kmeans = KMeans(n_clusters=n_clusters, init='k-means++', random_state=42)
kmeans.fit(X_scaled)

df['Cluster'] = kmeans.labels_
print("\nClustered Dataset:")
print(df[['ID', 'Cluster']])

#Using PCA determing the graph(one method of deriving the graph)
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)
centroids = kmeans.cluster_centers_
centroids_pca = pca.transform(centroids)
plt.figure(figsize=(10, 6))
for cluster in range(n_clusters):
    plt.scatter(X_pca[df['Cluster'] == cluster, 0], X_pca[df['Cluster'] == cluster, 1], label=f'Cluster {cluster}')
plt.scatter(centroids_pca[:, 0], centroids_pca[:, 1], color='purple', marker='*', label='Centroid')
plt.title('Clustering of Customers (PCA)')
plt.xlabel('Pc_1')
plt.ylabel('Pc_2')
plt.legend()
plt.grid(True)
plt.show()

#deriving Silhouette_score
from sklearn.metrics import silhouette_score
sse = []
sil_score=[]
k_nrg=range(1,10)
for k in range(1,10):
   kmeans = KMeans(n_clusters=k)
   kmeans.fit(df)
   sse.append(kmeans.inertia_)
   if k>=2:
    x=silhouette_score(df, kmeans.fit_predict(df))
    sil_score.append(x)
plt.xlabel('K')
plt.ylabel('Sum of squared error')
plt.plot(sse)
plt.show()
plt.xlabel('K')
plt.ylabel('Silhouette Score')
plt.plot(range(2,10),sil_score,color='red')
plt.show()